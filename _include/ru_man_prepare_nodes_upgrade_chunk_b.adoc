= 
:allow-uri-read: 


. Registre el modelo, el ID de sistema y el número de serie de ambos nodos:
+
`system node show -node _node1,node2_ -instance`

+

NOTE: Utilizará la información para reasignar discos y retirar los nodos originales.

. Escriba el siguiente comando en los nodos 1 y 2, y registre información sobre las bandejas, el número de discos de cada bandeja, los detalles del almacenamiento flash, la memoria, la NVRAM y las tarjetas de red de los resultados:
+
`run -node _node_name_ sysconfig`

+

NOTE: Puede utilizar la información para identificar piezas o accesorios que desee transferir al nodo 3 o al nodo 4.

. Escriba el siguiente comando en el nodo 1 y en el nodo 2, y registre los agregados que están en línea en ambos nodos:
+
`storage aggregate show -node _node_name_ -state online`

+

NOTE: Puede utilizar esta información y la información del siguiente subpaso para comprobar que los agregados y volúmenes permanecen en línea durante el procedimiento, excepto durante el breve período en el que se encuentran sin conexión durante la reubicación.

. [[man_prepare_Nodes_step19]]Introduzca el siguiente comando en los nodos 1 y 2 y registre los volúmenes que están sin conexión en ambos nodos:
+
`volume show -node _node_name_ -state offline`

+

NOTE: Después de la actualización, se volverá a ejecutar el comando y se comparará el resultado con el resultado de este paso para ver si otros volúmenes se han desconectado.

+
.. Introduzca los siguientes comandos para ver si hay grupos de interfaces o VLAN configurados en el nodo 1 o el nodo 2:
+
`network port ifgrp show`

+
`network port vlan show`

+
Tenga en cuenta si los grupos de interfaces o las VLAN están configurados en el nodo 1 o el nodo 2, necesita esa información en el siguiente paso y, más adelante, en el procedimiento.

.. Complete los siguientes subpasos en el nodo 1 y en el nodo 2 para confirmar que los puertos físicos se pueden asignar correctamente más adelante en el procedimiento:


. Introduzca el siguiente comando para ver si hay grupos de conmutación al nodo de respaldo en el nodo distinto de `clusterwide`:
+
`network interface failover-groups show`

+
Los grupos de recuperación tras fallos son conjuntos de puertos de red presentes en el sistema. Como al actualizar el hardware de la controladora puede cambiar la ubicación de los puertos físicos, los grupos de conmutación por error pueden cambiarse inadvertidamente durante la actualización.

+
El sistema muestra los grupos de conmutación por error en el nodo, como se muestra en el ejemplo siguiente:

+
....
cluster::> network interface failover-groups show

Vserver             Group             Targets
------------------- ----------------- ----------
Cluster             Cluster           node1:e0a, node1:e0b
                                      node2:e0a, node2:e0b

fg_6210_e0c         Default           node1:e0c, node1:e0d
                                      node1:e0e, node2:e0c
                                      node2:e0d, node2:e0e

2 entries were displayed.
....
. Si hay grupos de conmutación por error presentes diferentes de `clusterwide`, registre los nombres de los grupos de conmutación por error y los puertos que pertenecen a los grupos de conmutación por error.
. Introduzca el siguiente comando para ver si hay alguna VLAN configurada en el nodo:
+
`network port vlan show -node _node_name_`

+
Las VLAN se configuran mediante puertos físicos. Si cambian los puertos físicos, deberán volver a crear las VLAN más adelante en este procedimiento.

+
El sistema muestra las VLAN que se han configurado en el nodo, como se muestra en el ejemplo siguiente:

+
....
cluster::> network port vlan show

Network Network
Node    VLAN Name Port    VLAN ID MAC Address
------  --------- ------- ------- ------------------
node1   e1b-70    e1b     70      00:15:17:76:7b:69
....
. Si hay VLAN configuradas en el nodo, anote cada emparejamiento de puertos de red e ID de VLAN.
+
.. Realice una de las siguientes acciones:
+
[cols="35,65"]
|===
| Si los grupos de interfaces o VLAN son... | Realice lo siguiente... 


| En los nodos 1 o 2 | Completo <<man_prepare_nodes_step23,Paso 23>> y.. <<man_prepare_nodes_step24,Paso 24>>. 


| No en el nodo 1 o el nodo 2 | Vaya a. <<man_prepare_nodes_step24,Paso 24>>. 
|===
.. [[man_prepare_Nodes_step23]] Si no sabe si el nodo 1 y el nodo 2 están en un entorno SAN o no SAN, introduzca el siguiente comando y examine su salida:
+
`network interface show -vserver _vserver_name_ -data-protocol iscsi|fcp`

+
Si no hay ningún iSCSI ni FC configurado para la SVM, el comando mostrará un mensaje similar al siguiente ejemplo:

+
....
cluster::> network interface show -vserver Vserver8970 -data-protocol iscsi|fcp
There are no entries matching your query.
....
+
Puede confirmar que el nodo está en un entorno NAS mediante el `network interface show` con el `-data-protocol nfs|cifs` parámetros.

+
Si iSCSI o FC está configurado para la SVM, el comando mostrará un mensaje similar al siguiente ejemplo:

+
....
cluster::> network interface show -vserver vs1 -data-protocol iscsi|fcp

         Logical    Status     Network            Current  Current Is
Vserver  Interface  Admin/Oper Address/Mask       Node     Port    Home
-------- ---------- ---------- ------------------ -------- ------- ----
vs1      vs1_lif1   up/down    172.17.176.20/24   node1    0d      true
....
.. [[man_prepare_Nodes_step24]]Compruebe que todos los nodos del clúster están en quórum completando los siguientes subpasos:


. Introduzca el nivel de privilegio avanzado:
+
`set -privilege advanced`

+
El sistema muestra el siguiente mensaje:

+
....
Warning: These advanced commands are potentially dangerous; use them only when directed to do so by NetApp personnel.
Do you wish to continue? (y or n):
....
. Introduzca `y`.
. Compruebe el estado del servicio de clúster en el kernel, una vez para cada nodo:
+
`cluster kernel-service show`

+
El sistema muestra un mensaje similar al siguiente ejemplo:

+
....
cluster::*> cluster kernel-service show

Master        Cluster       Quorum        Availability  Operational
Node          Node          Status        Status        Status
------------- ------------- ------------- ------------- -------------
node1         node1         in-quorum     true          operational
              node2         in-quorum     true          operational

2 entries were displayed.
....
+
Los nodos de un clúster quórum cuando una mayoría simple de nodos están en buen estado y pueden comunicarse entre sí. Para obtener más información, consulte link:other_references.html["Referencias"] Para vincular a _System Administration Reference_.

. Volver al nivel de privilegio administrativo:
+
`set -privilege admin`

+
.. Realice una de las siguientes acciones:
+
[cols="35,65"]
|===
| Si el clúster... | Realice lo siguiente... 


| Tiene configurada LA San | Vaya a. <<man_prepare_nodes_step26,Paso 26>>. 


| No tiene configurada LA SAN | Vaya a. <<man_prepare_nodes_step29,Paso 29>>. 
|===
.. [[man_prepare_Nodes_step26]]Compruebe que hay LIF SAN en el nodo 1 y el nodo 2 para cada SVM con servicio SAN iSCSI o FC habilitado. Para ello, introduzca el siguiente comando y examine su salida:
+
`network interface show -data-protocol iscsi|fcp -home-node _node_name_`

+
El comando muestra información de la LIF DE SAN para el nodo 1 y el nodo 2. En los siguientes ejemplos, se muestra el estado de la columna Status Admin/Oper como up/up, lo que indica que EL servicio SAN iSCSI y FC está habilitado:

+
....
cluster::> network interface show -data-protocol iscsi|fcp
            Logical    Status     Network                  Current   Current Is
Vserver     Interface  Admin/Oper Address/Mask             Node      Port    Home
----------- ---------- ---------- ------------------       --------- ------- ----
a_vs_iscsi  data1      up/up      10.228.32.190/21         node1     e0a     true
            data2      up/up      10.228.32.192/21         node2     e0a     true

b_vs_fcp    data1      up/up      20:09:00:a0:98:19:9f:b0  node1     0c      true
            data2      up/up      20:0a:00:a0:98:19:9f:b0  node2     0c      true

c_vs_iscsi_fcp data1   up/up      20:0d:00:a0:98:19:9f:b0  node2     0c      true
            data2      up/up      20:0e:00:a0:98:19:9f:b0  node2     0c      true
            data3      up/up      10.228.34.190/21         node2     e0b     true
            data4      up/up      10.228.34.192/21         node2     e0b     true
....
+
También puede ver información más detallada de la LIF introduciendo el comando siguiente:

+
`network interface show -instance -data-protocol iscsi|fcp`

.. Capture la configuración predeterminada de cualquier puerto FC en los nodos originales introduciendo el siguiente comando y grabando la salida para sus sistemas:
+
`ucadmin show`

+
El comando muestra información sobre todos los puertos FC del clúster, como se muestra en el ejemplo siguiente:

+
....
cluster::> ucadmin show

                Current Current   Pending Pending   Admin
Node    Adapter Mode    Type      Mode    Type      Status
------- ------- ------- --------- ------- --------- -----------
node1   0a      fc      initiator -       -         online
node1   0b      fc      initiator -       -         online
node1   0c      fc      initiator -       -         online
node1   0d      fc      initiator -       -         online
node2   0a      fc      initiator -       -         online
node2   0b      fc      initiator -       -         online
node2   0c      fc      initiator -       -         online
node2   0d      fc      initiator -       -         online
8 entries were displayed.
....
+
Puede usar la información después de la actualización para establecer la configuración de los puertos de FC en los nodos nuevos.

.. [[man_prepare_nodes_step28]]Complete los siguientes subpasos:


. Introduzca el siguiente comando en uno de los nodos originales y registre el resultado:
+
`service-processor show -node * -instance`

+
El sistema muestra información detallada sobre el SP en ambos nodos.

. Confirme que el estado del SP es `online`.
. Confirme que la red del SP está configurada.
. Registre la dirección IP y otra información acerca del SP.
+
Tal vez desee reutilizar los parámetros de red de los dispositivos de gestión remota, en este caso los SPS, del sistema original para los SPS en los nuevos nodos. Para obtener información detallada sobre el SP, consulte link:other_references.html["Referencias"] Para establecer un vínculo a los comandos _System Administration Reference_ y _ONTAP 9: Manual Page Reference_.

+
.. [[man_prepare_nodes_step29]]Si desea que los nuevos nodos tengan la misma funcionalidad con licencia que los nodos originales, ingrese el siguiente comando para ver las licencias del clúster en el sistema original:
+
`system license show -owner *`

+
El siguiente ejemplo muestra las licencias de sitio para cluster1:

+
....
system license show -owner *
Serial Number: 1-80-000013
Owner: cluster1

Package           Type    Description           Expiration
----------------- ------- --------------------- -----------
Base              site    Cluster Base License  -
NFS               site    NFS License           -
CIFS              site    CIFS License          -
SnapMirror        site    SnapMirror License    -
FlexClone         site    FlexClone License     -
SnapVault         site    SnapVault License     -
6 entries were displayed.
....
.. Obtenga claves de licencia nuevas para los nodos nuevos en el _sitio de soporte de NetApp_. Consulte link:other_references.html["Referencias"] Para enlazar con _sitio de soporte de NetApp_.
+
Si el sitio no tiene las claves de licencia que necesita, póngase en contacto con su representante de ventas de NetApp.

.. Compruebe si el sistema original tiene AutoSupport habilitado. Para ello, introduzca el siguiente comando en cada nodo y examine su resultado:
+
`system node autosupport show -node _node1,node2_`

+
El resultado del comando muestra si AutoSupport está habilitado, como se muestra en el ejemplo siguiente:

+
....
cluster::> system node autosupport show -node node1,node2

Node             State     From          To                Mail Hosts
---------------- --------- ------------- ----------------  ----------
node1            enable    Postmaster    admin@netapp.com  mailhost

node2            enable    Postmaster    -                 mailhost
2 entries were displayed.
....
.. Realice una de las siguientes acciones:
+
[cols="35,65"]
|===
| Si el sistema original... | Realice lo siguiente... 


| Tiene AutoSupport habilitado...  a| 
Vaya a. <<man_prepare_nodes_step34,Paso 34>>.



| No tiene AutoSupport habilitado...  a| 
Habilite AutoSupport siguiendo las instrucciones de _System Administration Reference_. (Consulte link:other_references.html["Referencias"] Para establecer un vínculo a la _referencia de administración del sistema_.)

*Nota:* AutoSupport se activa de forma predeterminada cuando configura el sistema de almacenamiento por primera vez. Aunque puede deshabilitar AutoSupport en cualquier momento, debe dejarla habilitada. Habilitar AutoSupport puede ayudar de forma significativa a identificar problemas y soluciones cuando se producen fallos en el sistema de almacenamiento.

|===
.. [[man_prepare_Nodes_step34]]Compruebe que AutoSupport está configurado con los detalles del host de correo y los ID de correo electrónico del destinatario correctos introduciendo el siguiente comando en ambos nodos originales y examinando la salida:
+
`system node autosupport show -node node_name -instance`

+
Para obtener información detallada sobre AutoSupport, consulte link:other_references.html["Referencias"] Para establecer un vínculo a los comandos _System Administration Reference_ y _ONTAP 9: Manual Page Reference_.

.. [[man_prepare_Nodes_step35,Paso 35]]] Enviar un mensaje de AutoSupport a NetApp para el nodo 1 introduciendo el comando siguiente:
+
`system node autosupport invoke -node node1 -type all -message "Upgrading node1 from platform_old to platform_new"`

+

NOTE: No envíe un mensaje de AutoSupport a NetApp para el nodo 2 en este punto, ya que lo hará más adelante en el procedimiento.

.. [[man_prepare_Nodes_step36, Paso 36]] Compruebe que el mensaje de AutoSupport se ha enviado introduciendo el comando siguiente y examinando su salida:
+
`system node autosupport show -node _node1_ -instance`

+
Los campos `Last Subject Sent:` y.. `Last Time Sent:` contiene el título del mensaje del último mensaje enviado y la hora de envío del mensaje.

.. Si su sistema utiliza unidades de autocifrado, consulte el artículo de la base de conocimientos https://kb.netapp.com/onprem/ontap/Hardware/How_to_tell_if_a_drive_is_FIPS_certified["Cómo saber si una unidad tiene la certificación FIPS"^] Para determinar el tipo de unidades de autocifrado que se están utilizando en la pareja de alta disponibilidad que se está actualizando. El software ONTAP admite dos tipos de unidades de autocifrado:
+
--
*** Unidades SAS o NVMe con cifrado en almacenamiento de NetApp (NSE) certificado FIPS
*** Unidades NVMe (SED) con autocifrado no FIPS


[NOTE]
====
No es posible mezclar unidades FIPS con otros tipos de unidades en el mismo nodo o la pareja de alta disponibilidad.

Puede mezclar unidades de cifrado distinto de SED en el mismo nodo o par de alta disponibilidad.

====
https://docs.netapp.com/us-en/ontap/encryption-at-rest/support-storage-encryption-concept.html#supported-self-encrypting-drive-types["Obtenga más información sobre las unidades de autocifrado compatibles"^].

--



